# Transformers: State-of-the-art Natural Language Processing in Pytorch.
Check out [the library](https://github.com/huggingface/transformers) that was used to 
make this. These notebooks are pretty much an implementation of most of the techniques
portrayed in the documentation.

Please do spin these over [Google Colaboratory](https://colab.research.google.com/) or 
on any other GPU service providers as datasets and pre-trained model weights take up a 
consume a large amount of data and processing power.

Some of the techniques experimented with here are:
- ðŸ¤—Sequence Classification
- Language Modelling
- Named Entity Recognition
- Summarization
- Translation
- Extractive Question Answering
